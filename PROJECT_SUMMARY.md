# ðŸŽ¯ Complete Stratified Cox Model Package for Customer Repurchase Prediction

## ðŸ“¦ What You Have

**Stratified Cox Proportional Hazards model** for predicting customer repurchase behavior at the SKU/product level.

---

## ðŸ“ Files Included

### 1. **stratified_cox_repurchase_model.py** (24 KB)
**Complete end-to-end pipeline with all features**

âœ… Full data cleaning and preprocessing
âœ… Survival dataset creation (events + censoring)
âœ… Feature engineering (RECENCY, FREQUENCY, MONETARY, etc.)
âœ… Stratified AND non-stratified model training
âœ… Model comparison and evaluation
âœ… Customer ranking and risk scoring
âœ… Prediction at multiple time horizons (30, 60, 90 days)
âœ… Business insights generation
âœ… Visualization of survival curves

---

### 2. **cox_model_tutorial.py** (15 KB)
**Step-by-step tutorial with detailed explanations**

âœ… Commented code explaining each step
âœ… Simplified for learning and understanding
âœ… Progressive build-up of concepts
âœ… Console output showing results at each stage
âœ… Business recommendations included

---

### 3. **README_Cox_Model.md** (9.2 KB)
**Comprehensive documentation**

ðŸ“– Project overview and goals
ðŸ“– Dataset description and download instructions
ðŸ“– Installation and setup guide
ðŸ“– Pipeline explanation with diagrams
ðŸ“– Model details and mathematical formulas
ðŸ“– Business use cases and examples
ðŸ“– Customization options
ðŸ“– Key concepts glossary

---

### 4. **stratified_vs_nonstratified_guide.md** (16 KB)
**Deep dive into stratification concept**

ðŸ“Š Visual comparisons with ASCII diagrams
ðŸ“Š Mathematical formulas explained
ðŸ“Š Concrete numerical examples
ðŸ“Š When to use each approach
ðŸ“Š Code implementation differences
ðŸ“Š Interpretation differences
ðŸ“Š Decision tree for model selection

**Use this for:** Understanding why stratification matters for your use case

---

## ðŸš€ Quick Start Guide

### Step 1: Get the Dataset

Download the UCI Online Retail II dataset:

**Option A - Kaggle (Recommended):**
1. Go to: https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci
2. Click "Download"
3. Save as `online_retail_II.xlsx` in your project folder

**Option B - UCI Repository:**
1. Go to: https://archive.ics.uci.edu/dataset/352/online+retail
2. Download the dataset
3. Save as `online_retail_II.xlsx`

### Step 2: Install Dependencies

```bash
pip install pandas numpy matplotlib seaborn lifelines scikit-learn openpyxl
```

### Step 3: Run the Model

**For quick tutorial:**
```bash
python cox_model_tutorial.py
```

**For full pipeline:**
```bash
python stratified_cox_repurchase_model.py
```

### Step 4: View Results

Check the `/mnt/user-data/outputs/` directory for:
- `repurchase_predictions.csv` - Customer rankings per product
- `model_summary.csv` - Model performance metrics
- `survival_curves_product_*.png` - Visualization plots

---

## ðŸŽ“ Understanding Stratified Cox Models

### The Problem

In retail, different products have WILDLY different repurchase cycles:
- ðŸ¥› Milk: ~7 days
- ðŸ§´ Shampoo: ~30 days
- ðŸ§¥ Winter coat: ~365 days

A standard (non-stratified) Cox model forces all products to share the same baseline timing pattern. This is like saying milk and winter coats are repurchased on the same schedule! 

### The Solution: Stratification

**strata=['StockCode']** tells the model:
1. âœ… Give each product its own baseline hazard curve
2. âœ… But share customer behavior coefficients across products

**Why this works:**
- Products have different timing (captured in separate baselines)
- But customer behaviors are consistent (high-frequency customers buy ALL products more often)

### Visual Analogy

**Non-Stratified (Wrong):**
```
All Products Share One Curve:
    ^
    |     ___
    |    /   \___
    |___/_______\___> time
    
âŒ Milk, shampoo, coats all use this same curve!
```

**Stratified (Right):**
```
Each Product Has Its Own Curve:

Milk:      Shampoo:    Coat:
^          ^           ^
| _        |     __    |          __
|/ \       |    /  \   |         /  \
|___\      |___/____\  |________/____\
  7d         30d         365d
  
âœ… Realistic timing for each product!
```

---

## ðŸ’¼ Business Applications

### 1. Targeted Marketing Campaigns

**Customer Segmentation:**

| Segment | 30-Day Probability | Strategy |
|---------|-------------------|----------|
| ðŸ”´ High Intent | >60% | Gentle reminder email (no discount) |
| ðŸŸ¡ Medium Intent | 30-60% | 10-15% discount offer |
| ðŸŸ¢ Low Intent | <30% | Skip or re-engagement campaign |

**Implementation:**
```python
# High intent - ready to buy
high_intent = predictions[predictions['PROB_30D'] > 0.6]
send_email(high_intent, template='gentle_reminder')

# Medium intent - needs push
medium_intent = predictions[predictions['PROB_30D'].between(0.3, 0.6)]
send_email(medium_intent, template='discount_offer', discount=0.15)
```

### 2. Inventory & Demand Forecasting

```python
# Expected repurchases for each product in next 30 days
forecast = predictions.groupby('StockCode')['PROB_30D'].sum()

# Adjust inventory levels
for product, expected_demand in forecast.items():
    inventory_target = expected_demand * 1.2  # 20% buffer
    update_inventory(product, inventory_target)
```

### 3. Churn Prevention

```python
# Find high-value customers with low repurchase risk
at_risk = predictions[
    (predictions['RISK_SCORE'] < median_risk * 0.5) &
    (predictions['MONETARY'] > high_value_threshold)
]

# Proactive retention
send_email(at_risk, template='win_back', offer='exclusive_deal')
```

### 4. Product Bundling

```python
# Customers likely to buy Product A but not Product B
likely_a = predictions[
    (predictions['StockCode'] == 'PRODUCT_A') & 
    (predictions['PROB_30D'] > 0.6)
]

unlikely_b = predictions[
    (predictions['StockCode'] == 'PRODUCT_B') & 
    (predictions['PROB_30D'] < 0.3)
]

bundle_candidates = likely_a.merge(unlikely_b, on='CustomerID')
# Offer: "Buy A, get 20% off B"
```

---

## ðŸ“Š Expected Results

Based on similar implementations in the GitHub repositories I found:

### Model Performance
- **Concordance Index (C-index):** 0.70-0.75
  - Stratified model typically 5-10% better than non-stratified
  - Measures how well model ranks customer repurchase timing

### Feature Importance (Typical)
| Feature | Impact on Repurchase Risk |
|---------|---------------------------|
| PRODUCT_FREQUENCY | +35-45% per additional purchase |
| FREQUENCY | +25-35% per additional purchase |
| RECENCY | -10-20% per day since last purchase |
| MONETARY | +10-15% per unit increase |

### Business Impact (From Similar Projects)
- **archie-cm/Churn-Analysis-Ecommerce:** Avoided $900K loss, $150K revenue lift
- **archd3sai/Customer-Survival-Analysis:** Improved LTV prediction accuracy by 30%

---

## ðŸ”§ Customization Options

### Add More Features

In `engineer_features()` function:
```python
# Seasonality
survival_df['MONTH'] = survival_df['PurchaseDate'].dt.month
survival_df['IS_HOLIDAY_SEASON'] = survival_df['MONTH'].isin([11, 12])

# Category affinity
category_purchases = df.groupby(['CustomerID', 'Category'])['InvoiceNo'].nunique()
survival_df['CATEGORY_AFFINITY'] = ...

# Price sensitivity
avg_discount = df.groupby('CustomerID')['DiscountAmount'].mean()
survival_df['DISCOUNT_SENSITIVITY'] = ...
```

### Different Time Horizons

```python
# Predict at 7, 14, 30, 60, 90, 180 day horizons
time_horizons = [7, 14, 30, 60, 90, 180]

for horizon in time_horizons:
    product_df[f'PROB_{horizon}D'] = 1 - survival_func.loc[horizon].values
```

### Product Selection Criteria

```python
# Only use products with minimum 50 purchases
survival_df = create_repurchase_dataset(
    df_clean,
    min_purchases=2,
    min_product_purchases=50  # Adjust threshold
)

# Or select by revenue
top_revenue_products = df.groupby('StockCode')['Revenue'].sum().nlargest(20).index
model_df = survival_df[survival_df['StockCode'].isin(top_revenue_products)]
```
---

## ðŸš¨ Important Notes

### Data Requirements
- **Minimum events per product:** ~20-30 for stable baseline estimation
- **Minimum customers per product:** Varies, but more is better
- **Time span:** At least 2Ã— the expected repurchase cycle

### Model Assumptions
1. **Proportional hazards:** Customer effects are constant over time
   - Test with `proportional_hazard_test()`
2. **Independent observations:** Multiple purchases by same customer are independent
   - May need robust standard errors if violated

### Computational Considerations
- Stratification adds complexity: N baselines instead of 1
- Training time increases with number of strata
- For 1000+ products, consider stratifying by product category instead

---

## ðŸ“ˆ Next Steps

### 1. Validate Results
```python
# Compare predictions vs actuals
test_results = predictions.merge(actual_repurchases, on=['CustomerID', 'StockCode'])
accuracy = (test_results['PREDICTED_REPURCHASE'] == test_results['ACTUAL_REPURCHASE']).mean()
```

### 2. A/B Test Marketing Strategies
```python
# Test model-driven targeting vs random
control_group = random_sample(customers, n=1000)
treatment_group = high_intent_customers.head(1000)

# Measure lift in repurchase rate
lift = treatment_group['repurchase_rate'] / control_group['repurchase_rate']
```

### 3. Deploy to Production
```python
# Save model
import pickle
with open('cox_model.pkl', 'wb') as f:
    pickle.dump(cph_stratified, f)

# Create prediction API
from flask import Flask, request, jsonify

@app.route('/predict', methods=['POST'])
def predict_repurchase():
    customer_data = request.json
    risk_score = model.predict_partial_hazard(customer_data)
    return jsonify({'risk_score': risk_score})
```

### 4. Monitor and Retrain
```python
# Track model performance over time
monthly_concordance = []
for month in range(12):
    c_index = evaluate_model(model, data_month=month)
    monthly_concordance.append(c_index)

# Retrain if performance degrades
if monthly_concordance[-1] < 0.65:
    retrain_model(new_data)
```

---

## ðŸ’¡ Pro Tips

1. **Start with top 20-50 products** for initial model development
2. **Use log transformation** for skewed monetary features
3. **Standardize features** before fitting Cox model
4. **Check proportional hazards assumption** with visual plots
5. **Consider time-varying covariates** for seasonal effects
6. **Use robust standard errors** if multiple observations per customer
7. **Validate on holdout time period** (e.g., last month) not just random split

---

## ðŸ¤ Support & Resources

### Documentation
- **Lifelines:** https://lifelines.readthedocs.io/
- **UCI Dataset:** https://archive.ics.uci.edu/dataset/352/online+retail

### Learning Resources
- Cox, D. R. (1972). "Regression Models and Life-Tables"
- "Survival Analysis in Python" by Cameron Davidson-Pilon

### Community
- Lifelines GitHub Discussions
- Stats StackExchange (tag: survival-analysis)

---

## âœ… Summary

You now have everything needed to build a production-grade customer repurchase prediction system:

âœ… Complete working code (stratified Cox model)
âœ… Tutorial with step-by-step explanations
âœ… Comprehensive documentation
âœ… Deep dive into stratification concept
âœ… Business use cases and examples
âœ… Customization options
âœ… References to similar projects

**The stratified Cox model is perfect for your retail repurchase use case because:**
1. Products have very different repurchase cycles (milk vs coats)
2. Customer behaviors are consistent across products (frequent buyers buy everything more)
3. You want to rank customers per product for targeted marketing
4. You need timing predictions, not just yes/no classification

**Ready to get started? Run the tutorial script and see it in action! ðŸš€**
