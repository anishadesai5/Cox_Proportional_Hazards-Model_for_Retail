{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Cox Model - Step-by-Step Tutorial\n",
    "## Dataset: UCI Online Retail II\n",
    "\n",
    "**GOAL:** Predict which customers will repurchase which products and when\n",
    "\n",
    "### KEY INNOVATION: Stratified by product (SKU)\n",
    "- Each product gets its own baseline hazard curve\n",
    "- Customer features affect all products similarly\n",
    "\n",
    "This allows us to handle products with VERY different repurchase cycles:\n",
    "- Milk: ~7 days\n",
    "- Shampoo: ~30 days  \n",
    "- Winter coat: ~365 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 1: SETUP & DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UCI Online Retail Dataset...\n",
      "Loaded 1,067,371 transactions\n",
      "Columns: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Download from: https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci\n",
    "\n",
    "print(\"Loading UCI Online Retail Dataset...\")\n",
    "\n",
    "# Try to load from Excel or CSV\n",
    "df = pd.read_csv('online_retail_II.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} transactions\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489434</td>\n",
       "      <td>85048</td>\n",
       "      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.95</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323P</td>\n",
       "      <td>PINK CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323W</td>\n",
       "      <td>WHITE CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489434</td>\n",
       "      <td>22041</td>\n",
       "      <td>RECORD FRAME 7\" SINGLE SIZE</td>\n",
       "      <td>48</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489434</td>\n",
       "      <td>21232</td>\n",
       "      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n",
       "      <td>24</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice StockCode                          Description  Quantity  \\\n",
       "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
       "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
       "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
       "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
       "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
       "\n",
       "           InvoiceDate  Price  Customer ID         Country  \n",
       "0  2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
       "1  2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
       "2  2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
       "3  2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
       "4  2009-12-01 07:45:00   1.25      13085.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at data\n",
    "print(\"Sample Data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 2: DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Clean data: 779,425 transactions\n",
      "   Customers: 5,878\n",
      "   Products: 4,631\n",
      "   Date range: 2009-12-01 to 2011-12-09\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning data...\")\n",
    "\n",
    "# Remove cancellations (Invoice starts with 'C')\n",
    "df = df[~df['Invoice'].astype(str).str.startswith('C')]\n",
    "\n",
    "# Remove missing CustomerID\n",
    "df = df[df['Customer ID'].notna()]\n",
    "\n",
    "# Remove negative quantities/prices\n",
    "df = df[(df['Quantity'] > 0) & (df['Price'] > 0)]\n",
    "\n",
    "# Remove duplicate rows (EDA showed 3.22% duplicates)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert date\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Create revenue column\n",
    "df['Revenue'] = df['Quantity'] * df['Price']\n",
    "\n",
    "# Rename for convenience\n",
    "df = df.rename(columns={\n",
    "    'Invoice': 'InvoiceNo',\n",
    "    'StockCode': 'StockCode',\n",
    "    'Customer ID': 'CustomerID'\n",
    "})\n",
    "\n",
    "# Ensure StockCode is string type\n",
    "df['StockCode'] = df['StockCode'].astype(str)\n",
    "\n",
    "print(f\"Clean data: {len(df):,} transactions\")\n",
    "print(f\"   Customers: {df['CustomerID'].nunique():,}\")\n",
    "print(f\"   Products: {df['StockCode'].nunique():,}\")\n",
    "print(f\"   Date range: {df['InvoiceDate'].min().date()} to {df['InvoiceDate'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 3: CREATE SURVIVAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating survival analysis dataset...\n",
      "   For each customer-product pair, calculating:\n",
      "   - DURATION_DAYS: Days until next purchase (or censoring)\n",
      "   - EVENT: 1 = repurchased, 0 = censored\n",
      "   Using 3085 popular products\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating survival analysis dataset...\")\n",
    "print(\"   For each customer-product pair, calculating:\")\n",
    "print(\"   - DURATION_DAYS: Days until next purchase (or censoring)\")\n",
    "print(\"   - EVENT: 1 = repurchased, 0 = censored\")\n",
    "\n",
    "# Filter for products purchased frequently (min 30 times)\n",
    "product_counts = df['StockCode'].value_counts()\n",
    "popular_products = product_counts[product_counts >= 30].index\n",
    "df_filtered = df[df['StockCode'].isin(popular_products)].copy()\n",
    "\n",
    "print(f\"   Using {len(popular_products)} popular products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 729,256 survival records\n",
      "   Events (repurchases): 267,411\n",
      "   Censored: 461,845\n"
     ]
    }
   ],
   "source": [
    "# Sort by customer, product, date\n",
    "df_filtered = df_filtered.sort_values(['CustomerID', 'StockCode', 'InvoiceDate'])\n",
    "\n",
    "# Build survival records\n",
    "survival_records = []\n",
    "observation_end = df_filtered['InvoiceDate'].max()\n",
    "\n",
    "for (customer, product), group in df_filtered.groupby(['CustomerID', 'StockCode']):\n",
    "    \n",
    "    # Get purchase dates for this customer-product pair\n",
    "    dates = sorted(group['InvoiceDate'].unique())\n",
    "    \n",
    "    # Create records for consecutive purchases (EVENT=1)\n",
    "    for i in range(len(dates) - 1):\n",
    "        duration = (dates[i+1] - dates[i]).days\n",
    "        if 1 <= duration <= 365:  # Reasonable duration\n",
    "            survival_records.append({\n",
    "                'CustomerID': customer,\n",
    "                'StockCode': product,\n",
    "                'DURATION_DAYS': duration,\n",
    "                'EVENT': 1\n",
    "            })\n",
    "    \n",
    "    # Add censored observation (last purchase, EVENT=0)\n",
    "    last_date = dates[-1]\n",
    "    censored_duration = (observation_end - last_date).days\n",
    "    if censored_duration > 1:\n",
    "        survival_records.append({\n",
    "            'CustomerID': customer,\n",
    "            'StockCode': product,\n",
    "            'DURATION_DAYS': censored_duration,\n",
    "            'EVENT': 0\n",
    "        })\n",
    "\n",
    "survival_df = pd.DataFrame(survival_records)\n",
    "\n",
    "print(f\"\\nCreated {len(survival_df):,} survival records\")\n",
    "print(f\"   Events (repurchases): {survival_df['EVENT'].sum():,}\")\n",
    "print(f\"   Censored: {(survival_df['EVENT'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461845.0</td>\n",
       "      <td>308.27142</td>\n",
       "      <td>220.688332</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267411.0</td>\n",
       "      <td>86.69735</td>\n",
       "      <td>86.104399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean         std  min   25%    50%    75%    max\n",
       "EVENT                                                                 \n",
       "0      461845.0  308.27142  220.688332  2.0  86.0  311.0  477.0  738.0\n",
       "1      267411.0   86.69735   86.104399  1.0  24.0   55.0  120.0  365.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick stats\n",
    "print(\"Duration Statistics:\")\n",
    "survival_df.groupby('EVENT')['DURATION_DAYS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 4: FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n",
      "Features created:\n",
      "   - FREQUENCY\n",
      "   - LOG_MONETARY\n",
      "   - PRODUCT_FREQUENCY\n"
     ]
    }
   ],
   "source": [
    "print(\"Engineering features...\")\n",
    "\n",
    "# Calculate customer-level aggregations from original data\n",
    "customer_first_purchase = df.groupby('CustomerID')['InvoiceDate'].min()\n",
    "customer_purchase_count = df.groupby('CustomerID')['InvoiceNo'].nunique()\n",
    "customer_avg_revenue = df.groupby('CustomerID')['Revenue'].mean()\n",
    "\n",
    "# Calculate customer-product aggregations\n",
    "customer_product_count = df.groupby(['CustomerID', 'StockCode'])['InvoiceNo'].nunique()\n",
    "\n",
    "# Add features to survival dataframe\n",
    "# Note: For simplicity, using approximate values here\n",
    "# In production, you'd track exact values at time of each purchase\n",
    "\n",
    "survival_df['FREQUENCY'] = survival_df['CustomerID'].map(customer_purchase_count)\n",
    "survival_df['MONETARY'] = survival_df['CustomerID'].map(customer_avg_revenue)\n",
    "survival_df['PRODUCT_FREQUENCY'] = survival_df.apply(\n",
    "    lambda row: customer_product_count.get((row['CustomerID'], row['StockCode']), 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Log transform monetary (reduce skew)\n",
    "survival_df['LOG_MONETARY'] = np.log1p(survival_df['MONETARY'])\n",
    "\n",
    "# Normalize features\n",
    "feature_cols = ['FREQUENCY', 'LOG_MONETARY', 'PRODUCT_FREQUENCY']\n",
    "scaler = StandardScaler()\n",
    "survival_df[feature_cols] = scaler.fit_transform(survival_df[feature_cols])\n",
    "\n",
    "print(\"Features created:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"   - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>LOG_MONETARY</th>\n",
       "      <th>PRODUCT_FREQUENCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.292560e+05</td>\n",
       "      <td>7.292560e+05</td>\n",
       "      <td>7.292560e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.977234e-18</td>\n",
       "      <td>-1.097496e-16</td>\n",
       "      <td>-3.492032e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.819410e-01</td>\n",
       "      <td>-2.143993e+00</td>\n",
       "      <td>-4.610467e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.210138e-01</td>\n",
       "      <td>-7.561171e-01</td>\n",
       "      <td>-4.610467e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.143912e-01</td>\n",
       "      <td>8.190780e-02</td>\n",
       "      <td>-2.790326e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.011459e-01</td>\n",
       "      <td>5.238603e-01</td>\n",
       "      <td>8.499573e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.565085e+00</td>\n",
       "      <td>1.093330e+01</td>\n",
       "      <td>2.574899e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FREQUENCY  LOG_MONETARY  PRODUCT_FREQUENCY\n",
       "count  7.292560e+05  7.292560e+05       7.292560e+05\n",
       "mean   9.977234e-18 -1.097496e-16      -3.492032e-17\n",
       "std    1.000001e+00  1.000001e+00       1.000001e+00\n",
       "min   -4.819410e-01 -2.143993e+00      -4.610467e-01\n",
       "25%   -4.210138e-01 -7.561171e-01      -4.610467e-01\n",
       "50%   -3.143912e-01  8.190780e-02      -2.790326e-01\n",
       "75%   -1.011459e-01  5.238603e-01       8.499573e-02\n",
       "max    5.565085e+00  1.093330e+01       2.574899e+01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature Summary:\")\n",
    "survival_df[feature_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 5: SELECT TOP PRODUCTS FOR DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top 10 products for model:\n",
      "['85123A', '85099B', '22423', '20725', '84879', 'POST', '21212', '22383', '20727', '21232']\n",
      "Total records: 26,072\n"
     ]
    }
   ],
   "source": [
    "# Use top 10 products by number of events for cleaner demo\n",
    "top_products = survival_df[survival_df['EVENT'] == 1].groupby('StockCode').size().nlargest(10).index\n",
    "model_df = survival_df[survival_df['StockCode'].isin(top_products)].copy()\n",
    "\n",
    "print(f\"Using top {len(top_products)} products for model:\")\n",
    "print(top_products.tolist())\n",
    "print(f\"Total records: {len(model_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 6: TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split:\n",
      "   Train: 20,857 records\n",
      "   Test:  5,215 records\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(model_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train/Test Split:\")\n",
    "print(f\"   Train: {len(train_df):,} records\")\n",
    "print(f\"   Test:  {len(test_df):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 7: TRAIN STRATIFIED COX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING STRATIFIED COX PROPORTIONAL HAZARDS MODEL\n",
      "======================================================================\n",
      "\n",
      "KEY: Using strata=['StockCode']\n",
      "   -> Each product gets its own baseline hazard h0_product(t)\n",
      "   -> Customer features (beta) are shared across all products\n",
      "Iteration 1: norm_delta = 1.84e+00, step_size = 0.9500, log_lik = -95428.63590, newton_decrement = 7.87e+03, seconds_since_start = 0.4\n",
      "Iteration 2: norm_delta = 3.04e+00, step_size = 0.9500, log_lik = -120403.78774, newton_decrement = 5.73e+04, seconds_since_start = 0.7\n",
      "Iteration 3: norm_delta = 7.76e+00, step_size = 0.9500, log_lik = -108756.68722, newton_decrement = 4.57e+04, seconds_since_start = 0.8\n",
      "Iteration 4: norm_delta = 7.05e-01, step_size = 0.2327, log_lik = -94846.16476, newton_decrement = 2.91e+03, seconds_since_start = 1.0\n",
      "Iteration 5: norm_delta = 4.42e-01, step_size = 0.2965, log_lik = -93380.03471, newton_decrement = 1.33e+03, seconds_since_start = 1.1\n",
      "Iteration 6: norm_delta = 1.95e-01, step_size = 0.5011, log_lik = -92383.76186, newton_decrement = 3.19e+02, seconds_since_start = 1.2\n",
      "Iteration 7: norm_delta = 3.66e-02, step_size = 0.8469, log_lik = -92068.92281, newton_decrement = 1.28e+01, seconds_since_start = 1.4\n",
      "Iteration 8: norm_delta = 2.34e-03, step_size = 1.0000, log_lik = -92055.78825, newton_decrement = 2.67e-02, seconds_since_start = 1.6\n",
      "Iteration 9: norm_delta = 9.07e-06, step_size = 1.0000, log_lik = -92055.76148, newton_decrement = 2.81e-07, seconds_since_start = 1.7\n",
      "Iteration 10: norm_delta = 1.08e-10, step_size = 1.0000, log_lik = -92055.76148, newton_decrement = 3.70e-17, seconds_since_start = 1.9\n",
      "Convergence success after 10 iterations.\n",
      "\n",
      "Model trained!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING STRATIFIED COX PROPORTIONAL HAZARDS MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize model with small L2 penalty for stability\n",
    "cph_stratified = CoxPHFitter(penalizer=0.01)\n",
    "\n",
    "# Fit model with STRATIFICATION by product\n",
    "print(\"\\nKEY: Using strata=['StockCode']\")\n",
    "print(\"   -> Each product gets its own baseline hazard h0_product(t)\")\n",
    "print(\"   -> Customer features (beta) are shared across all products\")\n",
    "\n",
    "cph_stratified.fit(\n",
    "    train_df[feature_cols + ['DURATION_DAYS', 'EVENT', 'StockCode']],\n",
    "    duration_col='DURATION_DAYS',\n",
    "    event_col='EVENT',\n",
    "    strata=['StockCode'],  # STRATIFICATION\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(\"\\nModel trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lifelines.CoxPHFitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration col</th>\n",
       "      <td>'DURATION_DAYS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event col</th>\n",
       "      <td>'EVENT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalizer</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1 ratio</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strata</th>\n",
       "      <td>StockCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline estimation</th>\n",
       "      <td>breslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of observations</th>\n",
       "      <td>20857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of events observed</th>\n",
       "      <td>13497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial log-likelihood</th>\n",
       "      <td>-92055.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time fit was run</th>\n",
       "      <td>2026-02-05 01:20:46 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 12px;\"></th>\n",
       "      <th style=\"min-width: 12px;\">coef</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">cmp to</th>\n",
       "      <th style=\"min-width: 12px;\">z</th>\n",
       "      <th style=\"min-width: 12px;\">p</th>\n",
       "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FREQUENCY</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOG_MONETARY</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.13</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>39.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT_FREQUENCY</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.20</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Concordance</th>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial AIC</th>\n",
       "      <td>184117.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-likelihood ratio test</th>\n",
       "      <td>6745.75 on 3 df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-log2(p) of ll-ratio test</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrrrrrrrrrr}\n",
       " & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\n",
       "covariate &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
       "FREQUENCY & -0.01 & 0.99 & 0.01 & -0.04 & 0.02 & 0.96 & 1.02 & 0.00 & -0.87 & 0.39 & 1.38 \\\\\n",
       "LOG_MONETARY & 0.06 & 1.06 & 0.01 & 0.05 & 0.08 & 1.05 & 1.08 & 0.00 & 7.13 & 0.00 & 39.85 \\\\\n",
       "PRODUCT_FREQUENCY & 0.35 & 1.41 & 0.01 & 0.34 & 0.36 & 1.40 & 1.43 & 0.00 & 65.20 & 0.00 & inf \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 20857 total observations, 7360 right-censored observations>\n",
       "             duration col = 'DURATION_DAYS'\n",
       "                event col = 'EVENT'\n",
       "                penalizer = 0.01\n",
       "                 l1 ratio = 0.0\n",
       "                   strata = StockCode\n",
       "      baseline estimation = breslow\n",
       "   number of observations = 20857\n",
       "number of events observed = 13497\n",
       "   partial log-likelihood = -92055.76\n",
       "         time fit was run = 2026-02-05 01:20:46 UTC\n",
       "\n",
       "---\n",
       "                   coef exp(coef)  se(coef)  coef lower 95%  coef upper 95% exp(coef) lower 95% exp(coef) upper 95%\n",
       "covariate                                                                                                          \n",
       "FREQUENCY         -0.01      0.99      0.01           -0.04            0.02                0.96                1.02\n",
       "LOG_MONETARY       0.06      1.06      0.01            0.05            0.08                1.05                1.08\n",
       "PRODUCT_FREQUENCY  0.35      1.41      0.01            0.34            0.36                1.40                1.43\n",
       "\n",
       "                   cmp to     z      p  -log2(p)\n",
       "covariate                                       \n",
       "FREQUENCY            0.00 -0.87   0.39      1.38\n",
       "LOG_MONETARY         0.00  7.13 <0.005     39.85\n",
       "PRODUCT_FREQUENCY    0.00 65.20 <0.005       inf\n",
       "---\n",
       "Concordance = 0.78\n",
       "Partial AIC = 184117.52\n",
       "log-likelihood ratio test = 6745.75 on 3 df\n",
       "-log2(p) of ll-ratio test = inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "cph_stratified.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 8: COMPARE WITH NON-STRATIFIED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARISON: STRATIFIED vs NON-STRATIFIED\n",
      "======================================================================\n",
      "\n",
      "STRATIFIED MODEL:\n",
      "   Train C-index: 0.7811\n",
      "   Test C-index:  0.7824\n",
      "\n",
      "NON-STRATIFIED MODEL:\n",
      "   Train C-index: 0.3509\n",
      "   Test C-index:  0.3499\n",
      "\n",
      "WINNER: STRATIFIED\n",
      "   Improvement: 43.26 percentage points\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPARISON: STRATIFIED vs NON-STRATIFIED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train non-stratified model\n",
    "cph_unstratified = CoxPHFitter(penalizer=0.01)\n",
    "cph_unstratified.fit(\n",
    "    train_df[feature_cols + ['DURATION_DAYS', 'EVENT']],\n",
    "    duration_col='DURATION_DAYS',\n",
    "    event_col='EVENT'\n",
    ")\n",
    "\n",
    "# Evaluate both models using concordance_index_ (train) and score with scoring_method (test)\n",
    "train_c_strat = cph_stratified.concordance_index_\n",
    "train_c_unstrat = cph_unstratified.concordance_index_\n",
    "\n",
    "# For test set evaluation, use scoring_method='concordance_index'\n",
    "test_c_strat = cph_stratified.score(\n",
    "    test_df[feature_cols + ['DURATION_DAYS', 'EVENT', 'StockCode']], \n",
    "    scoring_method='concordance_index'\n",
    ")\n",
    "test_c_unstrat = cph_unstratified.score(\n",
    "    test_df[feature_cols + ['DURATION_DAYS', 'EVENT']], \n",
    "    scoring_method='concordance_index'\n",
    ")\n",
    "\n",
    "print(f\"\\nSTRATIFIED MODEL:\")\n",
    "print(f\"   Train C-index: {train_c_strat:.4f}\")\n",
    "print(f\"   Test C-index:  {test_c_strat:.4f}\")\n",
    "\n",
    "print(f\"\\nNON-STRATIFIED MODEL:\")\n",
    "print(f\"   Train C-index: {train_c_unstrat:.4f}\")\n",
    "print(f\"   Test C-index:  {test_c_unstrat:.4f}\")\n",
    "\n",
    "improvement = (test_c_strat - test_c_unstrat) * 100\n",
    "print(f\"\\nWINNER: {'STRATIFIED' if improvement > 0 else 'NON-STRATIFIED'}\")\n",
    "print(f\"   Improvement: {improvement:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why stratified is better:\n",
      "   -> Captures product-specific repurchase cycles\n",
      "   -> Milk (7 days) vs Shampoo (30 days) vs Coat (365 days)\n",
      "   -> More accurate predictions for diverse product portfolios\n"
     ]
    }
   ],
   "source": [
    "print(\"Why stratified is better:\")\n",
    "print(\"   -> Captures product-specific repurchase cycles\")\n",
    "print(\"   -> Milk (7 days) vs Shampoo (30 days) vs Coat (365 days)\")\n",
    "print(\"   -> More accurate predictions for diverse product portfolios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 9: MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREDICTING CUSTOMER REPURCHASE RISK\n",
      "======================================================================\n",
      "\n",
      "Baseline survival columns (first 3): ['20725', '20727', '21212']\n",
      "Column type: <class 'str'>\n",
      "\n",
      "Product: 85123A\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 customers most likely to repurchase:\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 21.29\n",
      "   - 30-day prob: 98.9%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 21.29\n",
      "   - 30-day prob: 98.9%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 21.29\n",
      "   - 30-day prob: 98.9%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 21.29\n",
      "   - 30-day prob: 98.9%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 21.29\n",
      "   - 30-day prob: 98.9%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "Product: 85099B\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 customers most likely to repurchase:\n",
      "\n",
      "   Customer 17841\n",
      "   - Risk Score: 10.42\n",
      "   - 30-day prob: 87.8%\n",
      "   - 60-day prob: 99.5%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 17841\n",
      "   - Risk Score: 10.42\n",
      "   - 30-day prob: 87.8%\n",
      "   - 60-day prob: 99.5%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 17841\n",
      "   - Risk Score: 10.42\n",
      "   - 30-day prob: 87.8%\n",
      "   - 60-day prob: 99.5%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 17841\n",
      "   - Risk Score: 10.42\n",
      "   - 30-day prob: 87.8%\n",
      "   - 60-day prob: 99.5%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 17841\n",
      "   - Risk Score: 10.42\n",
      "   - 30-day prob: 87.8%\n",
      "   - 60-day prob: 99.5%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "Product: 22423\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 customers most likely to repurchase:\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 193.34\n",
      "   - 30-day prob: 100.0%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 193.34\n",
      "   - 30-day prob: 100.0%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 193.34\n",
      "   - 30-day prob: 100.0%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 193.34\n",
      "   - 30-day prob: 100.0%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "   Customer 14911\n",
      "   - Risk Score: 193.34\n",
      "   - 30-day prob: 100.0%\n",
      "   - 60-day prob: 100.0%\n",
      "   - 90-day prob: 100.0%\n",
      "   - Actually repurchased: Yes\n",
      "\n",
      "\n",
      "Total predictions generated: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PREDICTING CUSTOMER REPURCHASE RISK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get baseline survival - check column format\n",
    "baseline_survival = cph_stratified.baseline_survival_\n",
    "print(f\"\\nBaseline survival columns (first 3): {list(baseline_survival.columns[:3])}\")\n",
    "print(f\"Column type: {type(baseline_survival.columns[0])}\")\n",
    "\n",
    "# For stratified models, columns may be tuples like ('85123A',) or just strings\n",
    "# Convert to dict for easier lookup\n",
    "if isinstance(baseline_survival.columns[0], tuple):\n",
    "    # Columns are tuples - extract the StockCode value\n",
    "    baseline_dict = {col[0]: baseline_survival[col] for col in baseline_survival.columns}\n",
    "    print(\"Note: Baseline columns are tuples, extracting first element\")\n",
    "else:\n",
    "    baseline_dict = {col: baseline_survival[col] for col in baseline_survival.columns}\n",
    "\n",
    "results = []\n",
    "\n",
    "for product in top_products[:3]:  # Demo with 3 products\n",
    "    print(f\"\\nProduct: {product}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    product_str = str(product)\n",
    "    \n",
    "    # Get customers who purchased this product\n",
    "    product_df = test_df[test_df['StockCode'] == product_str].copy()\n",
    "    \n",
    "    if len(product_df) == 0:\n",
    "        print(\"   No test data for this product\")\n",
    "        continue\n",
    "    \n",
    "    # Check if baseline exists for this product\n",
    "    if product_str not in baseline_dict:\n",
    "        print(f\"   Warning: No baseline survival for product {product_str}\")\n",
    "        print(f\"   Available products: {list(baseline_dict.keys())[:5]}...\")\n",
    "        continue\n",
    "    \n",
    "    # Predict partial hazard (risk scores) - exp(X*beta)\n",
    "    partial_hazard = cph_stratified.predict_partial_hazard(product_df[feature_cols])\n",
    "    product_df['RISK_SCORE'] = partial_hazard.values\n",
    "    \n",
    "    # Get baseline survival for this product\n",
    "    baseline_surv_product = baseline_dict[product_str]\n",
    "    \n",
    "    # Calculate survival probabilities: S(t|X) = S_0(t)^exp(X*beta)\n",
    "    for horizon in [30, 60, 90]:\n",
    "        valid_times = baseline_surv_product.index[baseline_surv_product.index <= horizon]\n",
    "        closest_time = valid_times.max() if len(valid_times) > 0 else baseline_surv_product.index.min()\n",
    "        \n",
    "        base_surv_at_t = baseline_surv_product.loc[closest_time]\n",
    "        survival_probs = base_surv_at_t ** partial_hazard.values\n",
    "        product_df[f'PROB_{horizon}D'] = 1 - survival_probs\n",
    "    \n",
    "    # Sort by risk (highest first)\n",
    "    product_df = product_df.sort_values('RISK_SCORE', ascending=False)\n",
    "    \n",
    "    # Show top 5 customers\n",
    "    print(\"\\nTop 5 customers most likely to repurchase:\")\n",
    "    for idx, row in product_df.head(5).iterrows():\n",
    "        print(f\"\\n   Customer {int(row['CustomerID'])}\")\n",
    "        print(f\"   - Risk Score: {row['RISK_SCORE']:.2f}\")\n",
    "        print(f\"   - 30-day prob: {row['PROB_30D']:.1%}\")\n",
    "        print(f\"   - 60-day prob: {row['PROB_60D']:.1%}\")\n",
    "        print(f\"   - 90-day prob: {row['PROB_90D']:.1%}\")\n",
    "        print(f\"   - Actually repurchased: {'Yes' if row['EVENT'] == 1 else 'No (censored)'}\")\n",
    "    \n",
    "    # Store results\n",
    "    for _, row in product_df.head(10).iterrows():\n",
    "        results.append({\n",
    "            'StockCode': product,\n",
    "            'CustomerID': row['CustomerID'],\n",
    "            'RISK_SCORE': row['RISK_SCORE'],\n",
    "            'PROB_30D': row['PROB_30D'],\n",
    "            'PROB_60D': row['PROB_60D'],\n",
    "            'PROB_90D': row['PROB_90D'],\n",
    "            'EVENT': row['EVENT']\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n\\nTotal predictions generated: {len(results_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 10: BUSINESS INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BUSINESS INSIGHTS & ACTIONABLE RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "1. MOST IMPORTANT FACTORS:\n",
      "                       coef  exp(coef)             p\n",
      "covariate                                           \n",
      "PRODUCT_FREQUENCY  0.346321   1.413857  0.000000e+00\n",
      "LOG_MONETARY       0.062093   1.064061  1.010849e-12\n",
      "FREQUENCY         -0.012067   0.988006  3.854350e-01\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BUSINESS INSIGHTS & ACTIONABLE RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Feature importance\n",
    "print(\"\\n1. MOST IMPORTANT FACTORS:\")\n",
    "coef_summary = cph_stratified.summary[['coef', 'exp(coef)', 'p']].sort_values('coef', key=abs, ascending=False)\n",
    "print(coef_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpretation:\n",
      "\n",
      "  PRODUCT_FREQUENCY:\n",
      "  - INCREASES repurchase risk by 41.4% per unit\n",
      "  - Hazard Ratio: 1.414\n",
      "  - Statistically significant (p=0.0000)\n",
      "\n",
      "  LOG_MONETARY:\n",
      "  - INCREASES repurchase risk by 6.4% per unit\n",
      "  - Hazard Ratio: 1.064\n",
      "  - Statistically significant (p=0.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Interpretation:\")\n",
    "for feature in coef_summary.index:\n",
    "    coef = coef_summary.loc[feature, 'coef']\n",
    "    hr = coef_summary.loc[feature, 'exp(coef)']\n",
    "    p = coef_summary.loc[feature, 'p']\n",
    "    \n",
    "    if p < 0.05:\n",
    "        direction = \"INCREASES\" if coef > 0 else \"DECREASES\"\n",
    "        print(f\"\\n  {feature}:\")\n",
    "        print(f\"  - {direction} repurchase risk by {abs((hr-1)*100):.1f}% per unit\")\n",
    "        print(f\"  - Hazard Ratio: {hr:.3f}\")\n",
    "        print(f\"  - Statistically significant (p={p:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. CUSTOMER TARGETING STRATEGY:\n",
      "\n",
      "   HIGH INTENT (>60% in 30 days): 30 customers\n",
      "      -> Send gentle reminder email\n",
      "      -> No discount needed (already primed)\n",
      "\n",
      "   MEDIUM INTENT (30-60% in 30 days): 0 customers\n",
      "      -> Offer 10-15% discount\n",
      "      -> Personalized recommendations\n",
      "\n",
      "   LOW INTENT (<30% in 30 days): 0 customers\n",
      "      -> Skip for now\n",
      "      -> Try re-engagement later\n"
     ]
    }
   ],
   "source": [
    "# 2. Customer segmentation\n",
    "print(\"\\n2. CUSTOMER TARGETING STRATEGY:\")\n",
    "\n",
    "high_intent = results_df[results_df['PROB_30D'] > 0.6]\n",
    "medium_intent = results_df[(results_df['PROB_30D'] > 0.3) & (results_df['PROB_30D'] <= 0.6)]\n",
    "low_intent = results_df[results_df['PROB_30D'] <= 0.3]\n",
    "\n",
    "print(f\"\\n   HIGH INTENT (>60% in 30 days): {len(high_intent)} customers\")\n",
    "print(f\"      -> Send gentle reminder email\")\n",
    "print(f\"      -> No discount needed (already primed)\")\n",
    "\n",
    "print(f\"\\n   MEDIUM INTENT (30-60% in 30 days): {len(medium_intent)} customers\")\n",
    "print(f\"      -> Offer 10-15% discount\")\n",
    "print(f\"      -> Personalized recommendations\")\n",
    "\n",
    "print(f\"\\n   LOW INTENT (<30% in 30 days): {len(low_intent)} customers\")\n",
    "print(f\"      -> Skip for now\")\n",
    "print(f\"      -> Try re-engagement later\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DEMAND FORECASTING:\n",
      "\n",
      "   Expected repurchases in 30 days: 28\n",
      "   -> Use for inventory planning\n"
     ]
    }
   ],
   "source": [
    "# 3. Demand forecast\n",
    "print(\"\\n3. DEMAND FORECASTING:\")\n",
    "expected_30d = results_df['PROB_30D'].sum()\n",
    "print(f\"\\n   Expected repurchases in 30 days: {expected_30d:.0f}\")\n",
    "print(f\"   -> Use for inventory planning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 11: SAVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "Predictions saved to: repurchase_predictions.csv\n",
      "Summary saved to: model_summary.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save predictions\n",
    "output_path = 'repurchase_predictions.csv'\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nPredictions saved to: {output_path}\")\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'Total Records': len(survival_df),\n",
    "    'Products Analyzed': len(top_products),\n",
    "    'Train Size': len(train_df),\n",
    "    'Test Size': len(test_df),\n",
    "    'Model Type': 'Stratified Cox PH',\n",
    "    'Train C-index': train_c_strat,\n",
    "    'Test C-index': test_c_strat,\n",
    "    'Improvement vs Non-Stratified': f\"{improvement:.2f}%\"\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv('model_summary.csv', index=False)\n",
    "print(f\"Summary saved to: model_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "1. Review predictions in repurchase_predictions.csv\n",
      "2. Implement targeting strategy for high/medium/low intent customers\n",
      "3. Monitor actual vs predicted repurchase rates\n",
      "4. Refine features and retrain model with new data\n",
      "5. Deploy to production for real-time scoring\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Next steps:\n",
    "1. Review predictions in repurchase_predictions.csv\n",
    "2. Implement targeting strategy for high/medium/low intent customers\n",
    "3. Monitor actual vs predicted repurchase rates\n",
    "4. Refine features and retrain model with new data\n",
    "5. Deploy to production for real-time scoring\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
